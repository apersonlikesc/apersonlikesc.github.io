<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Microsoft YaHei:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|consolas:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png?v=5.1.4">


  <link rel="mask-icon" href="/images/safari-pinned-tab.svg?v=5.1.4" color="#222">


  <link rel="manifest" href="/images/site.manifest">


  <meta name="msapplication-config" content="/images/browserconfig.xml" />



  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="热爱生活的程序员">
<meta name="keywords" content="blog">
<meta property="og:type" content="website">
<meta property="og:title" content="Eden">
<meta property="og:url" content="https://www.unblog.top/page/12/index.html">
<meta property="og:site_name" content="Eden">
<meta property="og:description" content="热爱生活的程序员">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Eden">
<meta name="twitter:description" content="热爱生活的程序员">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"hide","offset":12,"b2t":false,"scrollpercent":false,"onmobile":true},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.unblog.top/page/12/"/>





  <title>Eden</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?070140e78adcb25cf2b649c2985789db";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Eden</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">中二少年的博客</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            公益404
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.unblog.top/2018/08/16/scrapy3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="兔子春">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eden">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/16/scrapy3/" itemprop="url">Scrapy Pass 3</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-16T18:59:48+08:00">
                2018-08-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-08-16T19:01:23+08:00">
                2018-08-16
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,368
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  15
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Learn-Scrapy-pass-3"><a href="#Learn-Scrapy-pass-3" class="headerlink" title="Learn Scrapy pass 3"></a>Learn Scrapy pass 3</h2><h3 id="接上文Extract-data"><a href="#接上文Extract-data" class="headerlink" title="接上文Extract data"></a>接上文Extract data</h3><h4 id="Extracting-quotes-and-authors"><a href="#Extracting-quotes-and-authors" class="headerlink" title="Extracting quotes and authors"></a>Extracting quotes and authors</h4><p>Now that you know a bit about <code>selection</code> and <code>extraction</code>, let’s complete our spider by writing the code to extract the quotes from the web page.</p>
<p>Each quote in <code>http://quotes.toscrape.com</code>is represented by HTML elements that look like this:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&lt;div class=&quot;quote&quot;&gt;</span><br><span class="line">    &lt;span class=&quot;text&quot;&gt;“The world as we have created it is a process of our</span><br><span class="line">    thinking. It cannot be changed without changing our thinking.”&lt;/span&gt;</span><br><span class="line">    &lt;span&gt;</span><br><span class="line">        by &lt;small class=&quot;author&quot;&gt;Albert Einstein&lt;/small&gt;</span><br><span class="line">        &lt;a href=&quot;/author/Albert-Einstein&quot;&gt;(about)&lt;/a&gt;</span><br><span class="line">    &lt;/span&gt;</span><br><span class="line">    &lt;div class=&quot;tags&quot;&gt;</span><br><span class="line">        Tags:</span><br><span class="line">        &lt;a class=&quot;tag&quot; href=&quot;/tag/change/page/1/&quot;&gt;change&lt;/a&gt;</span><br><span class="line">        &lt;a class=&quot;tag&quot; href=&quot;/tag/deep-thoughts/page/1/&quot;&gt;deep-thoughts&lt;/a&gt;</span><br><span class="line">        &lt;a class=&quot;tag&quot; href=&quot;/tag/thinking/page/1/&quot;&gt;thinking&lt;/a&gt;</span><br><span class="line">        &lt;a class=&quot;tag&quot; href=&quot;/tag/world/page/1/&quot;&gt;world&lt;/a&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure></p>
<p>Let’s open up scrapy shell and play a bit to find out how to extract the data we want:<br><code>$ scrapy shell &#39;http://quotes.toscrape.com&#39;</code><br>We get a <strong>list</strong> of selectors for the quote HTML elements with:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&quot;div.quote&quot;)</span><br></pre></td></tr></table></figure></p>
<p>Each of the selectors <strong>returned by the query</strong> above allows us to run further queries over their sub-elements. Let’s assign the first selector to a variable, so that we can run our CSS selectors directly on a particular quote:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; quote = response.css(&quot;div.quote&quot;)[0]</span><br></pre></td></tr></table></figure></p>
<p>Now, let’s extract title, author and the tags from that quote using the quote object we just created:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; title = quote.css(&quot;span.text::text&quot;).extract_first()</span><br><span class="line">&gt;&gt;&gt; title</span><br><span class="line">&apos;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&apos;</span><br><span class="line">&gt;&gt;&gt; author = quote.css(&quot;small.author::text&quot;).extract_first()</span><br><span class="line">&gt;&gt;&gt; author</span><br><span class="line">&apos;Albert Einstein&apos;</span><br></pre></td></tr></table></figure></p>
<p>Given that the tags are a <strong>list</strong> of strings, we can use the <code>.extract()</code> method to get all of them:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; tags = quote.css(&quot;div.tags a.tag::text&quot;).extract()</span><br><span class="line">&gt;&gt;&gt; tags</span><br><span class="line">[&apos;change&apos;, &apos;deep-thoughts&apos;, &apos;thinking&apos;, &apos;world&apos;]</span><br></pre></td></tr></table></figure></p>
<p>Having figured out how to extract each bit, we can now iterate over all the quotes elements and put them together into a Python dictionary:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; for quote in response.css(&quot;div.quote&quot;):</span><br><span class="line">...     text = quote.css(&quot;span.text::text&quot;).extract_first()</span><br><span class="line">...     author = quote.css(&quot;small.author::text&quot;).extract_first()</span><br><span class="line">...     tags = quote.css(&quot;div.tags a.tag::text&quot;).extract()</span><br><span class="line">...     print(dict(text=text, author=author, tags=tags))</span><br><span class="line">&#123;&apos;tags&apos;: [&apos;change&apos;, &apos;deep-thoughts&apos;, &apos;thinking&apos;, &apos;world&apos;], &apos;author&apos;: &apos;Albert Einstein&apos;, &apos;text&apos;: &apos;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&apos;&#125;</span><br><span class="line">&#123;&apos;tags&apos;: [&apos;abilities&apos;, &apos;choices&apos;], &apos;author&apos;: &apos;J.K. Rowling&apos;, &apos;text&apos;: &apos;“It is our choices, Harry, that show what we truly are, far more than our abilities.”&apos;&#125;</span><br><span class="line">    ... a few more of these, omitted for brevity</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="Extracting-data-in-our-spider"><a href="#Extracting-data-in-our-spider" class="headerlink" title="Extracting data in our spider"></a>Extracting data in our spider</h4><p>Let’s get back to our spider. Until now, it doesn’t extract any data in particular, just saves the whole HTML page to a local file <em>(额)</em> . Let’s integrate the extraction logic(逻辑) above into our spider.</p>
<p>A Scrapy spider typically <strong>generates many dictionaries</strong> containing the data extracted from the page. To do that, we use the <strong>yield</strong> Python keyword in the callback, as you can see below:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    start_urls = [</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/1/&apos;,</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/2/&apos;,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),</span><br><span class="line">                &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract(),</span><br><span class="line">            &#125;</span><br><span class="line">            (yield 不断调用,似乎不用储存)</span><br></pre></td></tr></table></figure></p>
<p>If you run this spider, it will output the extracted data with the log:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">&#123;&apos;tags&apos;: [&apos;life&apos;, &apos;love&apos;], &apos;author&apos;: &apos;André Gide&apos;, &apos;text&apos;: &apos;“It is better to be hated for what you are than to be loved for what you are not.”&apos;&#125;</span><br><span class="line">2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">&#123;&apos;tags&apos;: [&apos;edison&apos;, &apos;failure&apos;, &apos;inspirational&apos;, &apos;paraphrased&apos;], &apos;author&apos;: &apos;Thomas A. Edison&apos;, &apos;text&apos;: &quot;“I have not failed. I&apos;ve just found 10,000 ways that won&apos;t work.”&quot;&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="Storing-the-scraped-data"><a href="#Storing-the-scraped-data" class="headerlink" title="Storing the scraped data"></a>Storing the scraped data</h4><p>The simplest way to store the scraped data is by using <strong>Feed exports</strong>, with the following command:<br><code>scrapy crawl quotes -o quotes.json</code></p>
<p>That will generate an quotes.json file containing all scraped items, serialized in <code>JSON</code>.</p>
<p>For historic reasons, Scrapy <strong>appends to</strong> a given file <strong>instead of overwriting</strong> its contents. If you run this command twice without removing the file before the second time, you’ll end up with a broken JSON file.<br><strong>(两次使用会损坏json文件)</strong><br>You can also use other formats, like JSON Lines:<br><code>scrapy crawl quotes -o quotes.jl</code></p>
<blockquote>
<p>The JSON Lines format is useful because it’s <strong>stream-like</strong>, <strong>you can easily append new records to it.</strong> It doesn’t have the same problem of JSON when you run twice. Also, <strong>as each record is a separate line</strong>, you can process big files without having to fit everything in memory, there are tools like JQ to help doing that at the command-line.</p>
</blockquote>
<p>In small projects (like the one in this tutorial), that should be enough. However, if you want to <strong>perform more complex things with the scraped items, you can write an Item Pipeline</strong>. A placeholder file for Item Pipelines has been set up for you when the project is created, in tutorial/pipelines.py.<strong>(预先创建好了pipelines文件)</strong> Though you <strong>don’t need to implement any item pipelines</strong> if you just want to store the scraped items.</p>
<h4 id="Following-links"><a href="#Following-links" class="headerlink" title="Following links"></a>Following links</h4><p>Let’s say, instead of just scraping the stuff from the first two pages from <code>http://quotes.toscrape.com</code>, you want quotes from all the pages in the website.</p>
<p>Now that you know how to extract data from pages, let’s see how to follow links from them.</p>
<p>First thing is to extract the link to the page we want to follow. Examining our page, we can see there is a link to the next page with the following markup:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;ul class=&quot;pager&quot;&gt;</span><br><span class="line">    &lt;li class=&quot;next&quot;&gt;</span><br><span class="line">        &lt;a href=&quot;/page/2/&quot;&gt;Next &lt;span aria-hidden=&quot;true&quot;&gt;&amp;rarr;&lt;/span&gt;&lt;/a&gt;</span><br><span class="line">    &lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br></pre></td></tr></table></figure></p>
<p>We can try extracting it in the shell:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;li.next a&apos;).extract_first()</span><br><span class="line">&apos;&lt;a href=&quot;/page/2/&quot;&gt;Next &lt;span aria-hidden=&quot;true&quot;&gt;→&lt;/span&gt;&lt;/a&gt;&apos;</span><br></pre></td></tr></table></figure></p>
<p>This gets the anchor element, but we want the attribute href. For that, Scrapy supports a CSS extension that let’s you select the attribute contents, like this:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">&apos;/page/2/&apos;</span><br></pre></td></tr></table></figure></p>
<p>Let’s see now our spider modified to recursively follow the link to the next page, extracting data from it:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    start_urls = [</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/1/&apos;,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),</span><br><span class="line">                &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">        if next_page is not None:</span><br><span class="line">            next_page = response.urljoin(next_page)</span><br><span class="line">            yield scrapy.Request(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure></p>
<p>Now, after extracting the data, the parse() method looks for the link to the next page, builds a full absolute URL <strong>using the urljoin() method</strong> (since the links can be relative) and yields a new request to the next page, registering itself <strong>as callback</strong> to <strong>handle the data</strong> extraction for the next page and to keep the crawling going through all the pages.</p>
<p>What you see here is Scrapy’s mechanism(机制) of following links: <strong>when you yield a Request in a callback method, Scrapy will schedule that request to be sent and register a callback method to be executed when that request finishes.</strong></p>
<p>Using this, you can build complex crawlers that follow links according to rules you define, and extract different kinds of data depending on the page it’s visiting.</p>
<p>In our example, it creates a sort of loop, following all the links to the next page until it doesn’t find one – handy for crawling blogs, forums and other sites with pagination.</p>
<h4 id="A-shortcut-for-creating-Requests"><a href="#A-shortcut-for-creating-Requests" class="headerlink" title="A shortcut for creating Requests"></a>A shortcut for creating Requests</h4><p>As a shortcut for creating Request objects you can use response.follow:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    start_urls = [</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/1/&apos;,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;span small::text&apos;).extract_first(),</span><br><span class="line">                &apos;tags&apos;: quote.css(&apos;div.tags a.tag::text&apos;).extract(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">        if next_page is not None:</span><br><span class="line">            yield response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure></p>
<p>Unlike scrapy.Request, <strong>response.follow supports relative URLs directly - no need to call urljoin</strong>.(震惊,似乎挺厉害的) Note that response.follow just returns a Request instance; you still have to yield this Request.</p>
<p>You can also pass a selector to response.follow instead of a string; this selector should extract necessary attributes:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for href in response.css(&apos;li.next a::attr(href)&apos;):</span><br><span class="line">    yield response.follow(href, callback=self.parse)</span><br></pre></td></tr></table></figure></p>
<p>For <a> elements there is a shortcut: response.follow uses their href attribute automatically. So the code can be shortened further:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for a in response.css(&apos;li.next a&apos;):</span><br><span class="line">    yield response.follow(a, callback=self.parse)</span><br></pre></td></tr></table></figure></a></p>
<p><strong>Note</strong><br><code>response.follow(response.css(&#39;li.next a&#39;))</code> is not valid because <code>response.css</code> returns a list-like object with selectors for all results, not a single selector. A for loop like in the example above, or <code>response.follow(response.css(&#39;li.next a&#39;)[0])</code> is fine.</p>
<h4 id="More-examples-and-patterns"><a href="#More-examples-and-patterns" class="headerlink" title="More examples and patterns"></a>More examples and patterns</h4><p>Here is another spider that illustrates callbacks and following links, this time for scraping author information:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">class AuthorSpider(scrapy.Spider):</span><br><span class="line">    name = &apos;author&apos;</span><br><span class="line">    start_urls = [&apos;http://quotes.toscrape.com/&apos;]</span><br><span class="line">    def parse(self, response):</span><br><span class="line">        # follow links to author pages</span><br><span class="line">        for href in response.css(&apos;.author + a::attr(href)&apos;):</span><br><span class="line">            yield response.follow(href, self.parse_author)</span><br><span class="line"></span><br><span class="line">        # follow pagination links</span><br><span class="line">        for href in response.css(&apos;li.next a::attr(href)&apos;):</span><br><span class="line">            yield response.follow(href, self.parse)</span><br><span class="line"></span><br><span class="line">    def parse_author(self, response):</span><br><span class="line">        def extract_with_css(query):</span><br><span class="line">            return response.css(query).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        yield &#123;</span><br><span class="line">            &apos;name&apos;: extract_with_css(&apos;h3.author-title::text&apos;),</span><br><span class="line">            &apos;birthdate&apos;: extract_with_css(&apos;.author-born-date::text&apos;),</span><br><span class="line">            &apos;bio&apos;: extract_with_css(&apos;.author-description::text&apos;),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></p>
<p>This spider will start from the main page, it will follow all the links to the authors pages calling the parse_author callback for each of them, and also the pagination links with the parse callback as we saw before.</p>
<p>Here we’re passing callbacks to response.follow as positional arguments to make the code shorter; it also works for <code>scrapy.Request</code>.</p>
<p>The parse_author callback <strong>defines a helper function</strong> to extract and cleanup the data from a CSS query and yields the Python dict with the author data.</p>
<p>Another interesting thing this spider demonstrates(显示) is that, even if there are many quotes from the same author, we don’t need to worry about visiting the same author page multiple times. By default, Scrapy filters out duplicated requests to URLs already visited, avoiding the problem of hitting servers too much because of a programming mistake. This can be configured by the setting DUPEFILTER_CLASS.(不用担心死循环)</p>
<p>Hopefully by now you have a good understanding of how to use the mechanism of following links and callbacks with Scrapy.</p>
<p>As yet another example spider that leverages the mechanism of following links, check out the CrawlSpider class for a generic spider that implements a small rules engine that you can use to write your crawlers on top of it.(可以写自己的规则?是这个意思吧)<br>Also, a common pattern is to build an item with data from more than one page, using <a href="https://doc.scrapy.org/en/latest/topics/request-response.html#topics-request-response-ref-request-callback-arguments" target="_blank" rel="noopener">a trick to pass additional data to the callbacks</a>.</p>
<h4 id="Using-spider-arguments"><a href="#Using-spider-arguments" class="headerlink" title="Using spider arguments"></a>Using spider arguments</h4><p>You can provide command line arguments to your spiders by using the -a option when running them:<br><code>scrapy crawl quotes -o quotes-humor.json -a tag=humor</code><br>(使用-a选项 添加attr)<br>These arguments are passed to the Spider’s __init__ method and become spider attributes by default.</p>
<p>In this example, the value provided for the tag argument will be available via self.tag. You can use this to make your spider fetch only quotes with a specific tag, building the URL based on the argument:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    def start_requests(self):</span><br><span class="line">        url = &apos;http://quotes.toscrape.com/&apos;</span><br><span class="line">        tag = getattr(self, &apos;tag&apos;, None)</span><br><span class="line">        if tag is not None:</span><br><span class="line">            url = url + &apos;tag/&apos; + tag</span><br><span class="line">        yield scrapy.Request(url, self.parse)</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;small.author::text&apos;).extract_first(),</span><br><span class="line">            &#125;(先处理得到的文本)</span><br><span class="line">        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">        (再去获取下一个page)</span><br><span class="line">        if next_page is not None:</span><br><span class="line">            yield response.follow(next_page, self.parse)</span><br></pre></td></tr></table></figure></p>
<p>If you pass the <code>tag=humor</code> argument to this spider, you’ll notice that it will only visit URLs from the humor tag, such as <code>http://quotes.toscrape.com/tag/humor</code>.</p>
<p>You can learn more about <a href="https://doc.scrapy.org/en/latest/topics/spiders.html#spiderargs" target="_blank" rel="noopener">handling spider arguments here</a>.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.unblog.top/2018/08/16/scrapy2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="兔子春">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eden">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/16/scrapy2/" itemprop="url">Scrapy Pass 2</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-16T14:27:23+08:00">
                2018-08-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-08-17T14:31:01+08:00">
                2018-08-17
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,240
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  13
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Learn-Scrapy-pass-2"><a href="#Learn-Scrapy-pass-2" class="headerlink" title="Learn Scrapy pass 2"></a>Learn Scrapy pass 2</h2><h3 id="安装-虚拟环境"><a href="#安装-虚拟环境" class="headerlink" title="安装(虚拟环境)"></a>安装(虚拟环境)</h3><p>Python packages can be installed either globally (a.k.a system wide), or in user-space. We do not recommend installing scrapy system wide.<br><strong>(并不推荐把python package安装成系统的一部分)</strong></p>
<p>Instead, we recommend that you install scrapy within a so-called “<code>virtual environment</code>” (<code>virtualenv</code>). Virtualenvs allow you to not conflict with already-installed Python system packages (which could break some of your system tools and scripts), and still install packages normally with <code>pip</code> (without <code>sudo</code> and the likes).<strong>(不会对系统现有的包产生冲突,可以使用普通用户的形式进行安装)</strong></p>
<p>Once you have created a virtualenv, you can install scrapy inside it with <code>pip</code>, just like any other Python package.<br><strong>(这里不介绍安装env,提一下,pycharm控制台自带虚拟环境)</strong></p>
<blockquote>
<p>Python virtualenvs can be created to use Python 2 by default, or Python 3 by default.<br>If you want to install scrapy with Python 3, install scrapy within a Python 3 virtualenv.<br>And if you want to install scrapy with Python 2, install scrapy within a Python 2 virtualenv.</p>
</blockquote>
<h3 id="Scrapy-使用示例"><a href="#Scrapy-使用示例" class="headerlink" title="Scrapy 使用示例"></a>Scrapy 使用示例</h3><p>We are going to scrape <code>quotes.toscrape.com</code>, a website that lists quotes from famous authors.</p>
<p>This tutorial will walk you through these tasks:</p>
<ol>
<li>Creating a new Scrapy project</li>
<li>Writing a spider to crawl a site and extract data</li>
<li>Exporting the scraped data using the command line</li>
<li>Changing spider to recursively follow links</li>
<li>Using spider arguments</li>
</ol>
<h4 id="Creating-a-project"><a href="#Creating-a-project" class="headerlink" title="Creating a project"></a>Creating a project</h4><p><strong>Before</strong> you start scraping, you will have to set up a new <strong>Scrapy project</strong>. Enter a directory where you’d like to store your code and run:<code>scrapy startproject tutorial</code><br>This will create a tutorial directory with the following contents:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">得到默认的初始化目录</span><br><span class="line">tutorial/</span><br><span class="line">    scrapy.cfg            # deploy configuration file 配置文件</span><br><span class="line"></span><br><span class="line">    tutorial/             # project&apos;s Python module, you&apos;ll import your code from here</span><br><span class="line">        __init__.py</span><br><span class="line"></span><br><span class="line">        items.py          # project items definition file</span><br><span class="line"></span><br><span class="line">        middlewares.py    # project middlewares file</span><br><span class="line"></span><br><span class="line">        pipelines.py      # project pipelines file</span><br><span class="line"></span><br><span class="line">        settings.py       # project settings file 配置文件</span><br><span class="line"></span><br><span class="line">        spiders/          # a directory where you&apos;ll later put your spiders</span><br><span class="line">            __init__.py</span><br></pre></td></tr></table></figure></p>
<h4 id="Our-first-Spider"><a href="#Our-first-Spider" class="headerlink" title="Our first Spider"></a>Our first Spider</h4><p>Spiders are classes that you define and that Scrapy uses to scrape information from a website (or a group of websites). They must subclass scrapy.Spider and define the initial requests to make, optionally how to follow links in the pages, and how to parse the downloaded page content to extract data.<br><strong>(Spiders目录是自己定义的,通过爬虫来爬取website)</strong><br>This is the code for our first Spider. Save it in a file named <code>quotes_spider.py</code> under the <strong>(注意位置)</strong> <code>tutorial/spiders</code>directory in your project:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line"></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        urls = [</span><br><span class="line">            &apos;http://quotes.toscrape.com/page/1/&apos;,</span><br><span class="line">            &apos;http://quotes.toscrape.com/page/2/&apos;,</span><br><span class="line">        ]</span><br><span class="line">        for url in urls:</span><br><span class="line">            yield scrapy.Request(url=url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        page = response.url.split(&quot;/&quot;)[-2]</span><br><span class="line">        filename = &apos;quotes-%s.html&apos; % page</span><br><span class="line">        with open(filename, &apos;wb&apos;) as f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(&apos;Saved file %s&apos; % filename)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>一个带有 yield 的函数就是一个 generator，它和普通函数不同，生成一个 generator 看起来像函数调用，但不会执行任何函数代码，直到对其调用 next()（在 for 循环中会自动调用 next()）才开始执行。虽然执行流程仍按函数的流程执行，但每执行到一个 yield 语句就会中断，并返回一个迭代值，下次执行时从 yield 的下一个语句继续执行。看起来就好像一个函数在正常执行的过程中被 yield 中断了数次，每次中断都会通过 yield 返回当前的迭代值。</p>
</blockquote>
<blockquote>
<p>yield 的好处是显而易见的，把一个函数改写为一个 generator 就获得了迭代能力，比起用类的实例保存状态来计算下一个 next() 的值，不仅代码简洁，而且执行流程异常清晰。<br>As you can see, our Spider subclasses scrapy.Spider and defines some attributes and methods:</p>
</blockquote>
<p><strong>name:</strong></p>
<blockquote>
<p>identifies the Spider.(定义爬虫名字) It must be <strong>unique</strong> within a project, that is, you can’t set the same name for different Spiders.</p>
</blockquote>
<p><strong>start_requests():</strong></p>
<blockquote>
<p>must <strong>return an iterable of Requests</strong> (you can return <strong>a list of requests</strong> or <strong>write a generator function</strong>) which the Spider will <strong>begin</strong> to crawl from. Subsequent requests will be generated successively from these initial requests.</p>
</blockquote>
<p><strong>parse()</strong>:</p>
<blockquote>
<p>a method that will be called to <strong>handle the response downloaded</strong> for each of the requests made. The response parameter is an instance of TextResponse that holds the page content and has further helpful methods to handle it.</p>
</blockquote>
<blockquote>
<p>The parse() method usually parses the response, extracting the scraped data as dicts and also finding new URLs to follow and creating new requests (Request) from them.<strong>(提取信息并得到下一步url)</strong></p>
</blockquote>
<h4 id="How-to-run-our-spider"><a href="#How-to-run-our-spider" class="headerlink" title="How to run our spider"></a>How to run our spider</h4><p>To put our spider to work, go to the project’s top level directory and run:<code>scrapy crawl quotes</code>(quotes就是之前定义的name)<br>This command runs the spider with name quotes that we’ve just added, that will send some requests for the <code>quotes.toscrape.com</code> domain. You will get an output similar to this:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">... (omitted for brevity)</span><br><span class="line">2016-12-16 21:24:05 [scrapy.core.engine] INFO: Spider opened</span><br><span class="line">2016-12-16 21:24:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)</span><br><span class="line">2016-12-16 21:24:05 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023</span><br><span class="line">2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (404) &lt;GET http://quotes.toscrape.com/robots.txt&gt; (referer: None)</span><br><span class="line">2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/1/&gt; (referer: None)</span><br><span class="line">2016-12-16 21:24:05 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/2/&gt; (referer: None)</span><br><span class="line">2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-1.html</span><br><span class="line">2016-12-16 21:24:05 [quotes] DEBUG: Saved file quotes-2.html</span><br><span class="line">2016-12-16 21:24:05 [scrapy.core.engine] INFO: Closing spider (finished)</span><br></pre></td></tr></table></figure></p>
<p>Now, check the files in the current directory. You should notice that two new files have been created: <code>quotes-1.html</code> and <code>quotes-2.html</code>, with the content for the respective URLs, as our <code>parse</code> method instructs.</p>
<h4 id="What-just-happened-under-the-hood"><a href="#What-just-happened-under-the-hood" class="headerlink" title="What just happened under the hood?"></a>What just happened under the hood?</h4><p>Scrapy schedules the scrapy.Request objects returned by the start_requests method of the Spider. Upon receiving a response for each one, it instantiates Response objects and calls the callback method associated with the request (in this case, the parse method) passing the response as argument.<br><strong>(通过the start_requests method of the Spider将request的请求发出去,得到response,然后对于每个response调用callback)</strong></p>
<h3 id="A-shortcut-to-the-start-requests-method"><a href="#A-shortcut-to-the-start-requests-method" class="headerlink" title="A shortcut to the start_requests method"></a>A shortcut to the start_requests method</h3><p>Instead of implementing(执行) a <code>start_requests()</code> method that generates <code>scrapy.Request</code> objects from URLs, you can just define a <code>start_urls</code> class attribute with a list of URLs. <strong>This list will then be used by the default implementation of <code>start_requests()</code> to create the initial requests for your spider:</strong><br><strong>(这个start_urls会自动调用默认的方法去生成初始的requests)</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    start_urls = [</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/1/&apos;,</span><br><span class="line">        &apos;http://quotes.toscrape.com/page/2/&apos;,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        page = response.url.split(&quot;/&quot;)[-2]</span><br><span class="line">        filename = &apos;quotes-%s.html&apos; % page</span><br><span class="line">        with open(filename, &apos;wb&apos;) as f:</span><br><span class="line">            f.write(response.body)</span><br></pre></td></tr></table></figure></p>
<p>The <code>parse()</code> method will be called to handle each of the requests for those URLs, even though we haven’t explicitly told Scrapy to do so. This happens because parse() is <strong>Scrapy’s default callback method</strong>, which is called for requests without an explicitly assigned callback.<strong>(默认会处理response,无需明显调用)</strong></p>
<h4 id="Extracting-data"><a href="#Extracting-data" class="headerlink" title="Extracting data"></a>Extracting data</h4><p>The best way to learn how to extract data with Scrapy is trying selectors using the shell (Scrapy shell). Run:<br><code>scrapy shell &#39;http://quotes.toscrape.com/page/1/&#39;`</code><br>You will see something like:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[ ... Scrapy log here ... ]</span><br><span class="line">2016-09-19 12:09:27 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/1/&gt; (referer: None)</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x7fa91d888c90&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   request    &lt;GET http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">[s]   response   &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x7fa91d888c10&gt;</span><br><span class="line">[s]   spider     &lt;DefaultSpider &apos;default&apos; at 0x7fa91c8af990&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   shelp()           Shell help (print this help)</span><br><span class="line">[s]   fetch(req_or_url) Fetch request (or URL) and update local objects</span><br><span class="line">[s]   view(response)    View response in a browser</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>
<p>Using the shell, you can try selecting elements using CSS with the response object:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;title&apos;)</span><br><span class="line">[&lt;Selector xpath=&apos;descendant-or-self::title&apos; data=&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;&gt;]</span><br></pre></td></tr></table></figure></p>
<p>(弱弱的说一句,有点像选择器啊)<br>The result of running <code>response.css(&#39;title&#39;)</code> is a list-like object called SelectorList, which represents a list of Selector objects that wrap around XML/HTML elements and allow you to run further queries to fine-grain the selection or extract the data.<br>(果然)<br>To extract the text from the title above, you can do:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;title::text&apos;).extract()</span><br><span class="line">[&apos;Quotes to Scrape&apos;]</span><br></pre></td></tr></table></figure></p>
<p>There are two things to note here:<br>one is that we’ve added <code>::text</code> to the CSS query, to mean we want to select <strong>only</strong> the text elements directly inside <title> element. If we don’t specify <code>::text</code>, we’d get the full title element, including its tags:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;title&apos;).extract()</span><br><span class="line">[&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;]</span><br></pre></td></tr></table></figure></title></p>
<p>The other thing is that the result of calling .extract() is a <strong>list</strong>, because we’re dealing with an instance of SelectorList. When you know you just want the first result, as in this case, you can do:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;title::text&apos;).extract_first()</span><br><span class="line">&apos;Quotes to Scrape&apos;</span><br></pre></td></tr></table></figure></p>
<p>As an alternative, you could’ve written:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;title::text&apos;)[0].extract()</span><br><span class="line">&apos;Quotes to Scrape&apos;</span><br></pre></td></tr></table></figure></p>
<p>However, using <code>.extract_first()</code> avoids an <code>IndexError</code> and returns <code>None</code> <strong>when</strong> it <strong>doesn’t find</strong> any element matching the selection.</p>
<p>There’s a lesson here: for most scraping code, you want it to be resilient to errors due to things not being found on a page, so that even if some parts fail to be scraped, you can at least get some data.<br><strong>(即使你没有得到你想要的东西,你也可以得到一些data)</strong></p>
<p>Besides the <code>extract()</code> and <code>extract_first()</code> methods, you can also use the <code>re()</code> method to extract using regular expressions:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;title::text&apos;).re(r&apos;Quotes.*&apos;)</span><br><span class="line">[&apos;Quotes to Scrape&apos;]</span><br><span class="line">&gt;&gt;&gt; response.css(&apos;title::text&apos;).re(r&apos;Q\w+&apos;)</span><br><span class="line">[&apos;Quotes&apos;]</span><br><span class="line">&gt;&gt;&gt; response.css(&apos;title::text&apos;).re(r&apos;(\w+) to (\w+)&apos;)</span><br><span class="line">[&apos;Quotes&apos;, &apos;Scrape&apos;]</span><br></pre></td></tr></table></figure></p>
<p>In order to find the proper CSS selectors to use, you might find useful opening the response page from the shell in your web browser using <code>view(response)</code>. You can use your browser developer tools or extensions like Firebug (see sections about <a href="https://doc.scrapy.org/en/latest/topics/firebug.html#topics-firebug" target="_blank" rel="noopener">Using Firebug for scraping</a> and <a href="https://doc.scrapy.org/en/latest/topics/firefox.html#topics-firefox" target="_blank" rel="noopener">Using Firefox for scraping</a>).</p>
<p><a href="http://selectorgadget.com/" target="_blank" rel="noopener">Selector Gadget</a> is also a nice tool to quickly find CSS selector for visually selected elements, which works in many browsers.</p>
<p>不止可以使用css选择器,还可以使用xpath<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.xpath(&apos;//title&apos;)</span><br><span class="line">[&lt;Selector xpath=&apos;//title&apos; data=&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;&gt;]</span><br><span class="line">&gt;&gt;&gt; response.xpath(&apos;//title/text()&apos;).extract_first()</span><br><span class="line">&apos;Quotes to Scrape&apos;</span><br></pre></td></tr></table></figure></p>
<p>XPath expressions are very powerful, and are the foundation of Scrapy Selectors. In fact, CSS selectors are converted to XPath under-the-hood. You can see that if you read closely the text representation of the selector objects in the shell.(没想到啊,竟然是这样)</p>
<blockquote>
<p>we encourage you to learn XPath even if you already know how to construct CSS selectors, it will make scraping much easier.</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.unblog.top/2018/08/16/scrapy1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="兔子春">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eden">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/16/scrapy1/" itemprop="url">Scrapy Pass 1</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-16T14:26:02+08:00">
                2018-08-16
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-08-16T14:27:19+08:00">
                2018-08-16
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  650
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  4
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Learn-Scrapy-pass-1"><a href="#Learn-Scrapy-pass-1" class="headerlink" title="Learn Scrapy pass 1"></a>Learn Scrapy pass 1</h2><h3 id="Walk-through-of-an-example-spider"><a href="#Walk-through-of-an-example-spider" class="headerlink" title="Walk-through of an example spider"></a>Walk-through of an example spider</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line">    start_urls = [</span><br><span class="line">        &apos;http://quotes.toscrape.com/tag/humor/&apos;,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.xpath(&apos;span/small/text()&apos;).extract_first(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(&apos;li.next a::attr(&quot;href&quot;)&apos;).extract_first()</span><br><span class="line">        if next_page is not None:</span><br><span class="line">            yield response.follow(next_page, self.parse)</span><br></pre></td></tr></table></figure>
<p>Put this in a text file, name it to something like <code>quotes_spider.py</code> and run the spider using the <code>runspider</code> command:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy runspider quotes_spider.py -o quotes.json</span><br></pre></td></tr></table></figure></p>
<p>When this finishes you will have in the <code>quotes.json</code> file a list of the quotes in JSON format, containing text and author, looking like this (<strong>reformatted here for better readability</strong>):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">    &quot;author&quot;: &quot;Jane Austen&quot;,</span><br><span class="line">    &quot;text&quot;: &quot;\u201cThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.\u201d&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">    &quot;author&quot;: &quot;Groucho Marx&quot;,</span><br><span class="line">    &quot;text&quot;: &quot;\u201cOutside of a dog, a book is man&apos;s best friend. Inside of a dog it&apos;s too dark to read.\u201d&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">    &quot;author&quot;: &quot;Steve Martin&quot;,</span><br><span class="line">    &quot;text&quot;: &quot;\u201cA day without sunshine is like, you know, night.\u201d&quot;</span><br><span class="line">&#125;,</span><br><span class="line">...]</span><br></pre></td></tr></table></figure></p>
<p>When you ran the command <code>scrapy runspider quotes_spider.py</code>, Scrapy looked for a Spider definition inside it and ran it through its crawler engine.<strong>(在爬取引擎中运行爬虫)</strong></p>
<p>The crawl started by making requests to the URLs defined in the <code>start_urls</code> attribute (in this case, only the URL for quotes in humor category)<strong>(发送请求给<code>start_urls</code>)</strong> and called the default callback method <code>parse</code>, passing the response object as an argument.<strong>(回调函数处理<code>response</code>)</strong> In the parse callback, we loop through the quote elements using a CSS Selector <strong>(通过使用css选择器)</strong>, yield a Python dict with the extracted quote text and author<strong>(使用python字典去提取text文本与作者)</strong> , look for a link to the next page and schedule another request using the same <code>parse</code> method as callback.<strong>(找到下一个<code>page</code>,调用相同的<code>parse</code>)</strong></p>
<p>Here you notice one of the main advantages about Scrapy: requests are scheduled and processed asynchronously. This means that Scrapy doesn’t need to wait for a request to be finished and processed, it can send another request or do other things in the meantime. This also means that other requests can keep going even if some request fails or an error happens while handling it.<strong>(处理异步,请求储存在调度器里面,不知道是不是队列形式)</strong></p>
<p>While this enables you to do very fast crawls (sending multiple concurrent requests at the same time, in a fault-tolerant way) Scrapy also gives you control over the politeness of the crawl through a few settings. You can do things like setting a download delay between each request, limiting amount of concurrent requests per domain or per IP, and even using an auto-throttling extension that tries to figure out these automatically.<strong>(可控制性:可以控制scrapy每个域名,ip访问的数量等)</strong></p>
<p>This is using feed exports to generate the JSON file, you can easily change the export format (XML or CSV, for example) or the storage backend (FTP or Amazon S3, for example). You can also write an item pipeline to store the items in a database.<strong>(输出形式可以多样)</strong></p>
<p>还有等等等等的特性,先不了解(看了也不懂),之后学了再看看</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.unblog.top/2018/08/15/Bumblebee控制独显/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="兔子春">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/7.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Eden">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/15/Bumblebee控制独显/" itemprop="url">Bumblebee控制独显</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-08-15T22:36:51+08:00">
                2018-08-15
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2018-09-05T17:58:06+08:00">
                2018-09-05
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/linux/" itemprop="url" rel="index">
                    <span itemprop="name">linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  195
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  1
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Bumblebee使用控制独显"><a href="#Bumblebee使用控制独显" class="headerlink" title="Bumblebee使用控制独显"></a>Bumblebee使用控制独显</h3><h5 id="安装"><a href="#安装" class="headerlink" title="安装:"></a>安装:</h5><p><code>bumblebee</code> - 提供守护进程以及程序的主要安装包。<br><code>mesa</code> - 开源的 <code>OpenGL</code> 标准实现。<br>对于合适的NVIDIA驱动。<br><code>xf86-video-intel</code> - <code>Intel</code> 驱动（可选）。<br>对于32位程序 (必须启用Multilib）在64位机器上的支持，安装:</p>
<p><code>lib32-virtualgl</code> - 为32位应用提供的渲染/显示桥。<br><code>lib32-nvidia-utils</code> 或者 <code>lib32-nvidia-340xx-utils</code>（和64位对应）。<br>要使用<code>Bumblebee</code>，请确保添加你的用户到 <code>bumblebee</code> 组：<br><code>gpasswd -a user bumblebee</code><br>并启用(<strong>enable</strong>) <code>bumblebeed.service</code>。之后重启系统</p>
<p>可以明显的感受到风扇转速下降</p>
<p>重启之后<br><strong>测试</strong><br>安装 <code>mesa-demos</code>并使用 <code>glxgears</code> 测试 <code>Bumblebee</code> 是否工作：<br><code>optirun glxgears -info</code><br>看到有图形出现,并且风扇开始转动,独显开始工作,成功!!</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/11/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/21/">21</a><a class="extend next" rel="next" href="/page/13/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
      <div id="sidebar-dimmer"></div>
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/7.jpg"
                alt="兔子春" />
            
              <p class="site-author-name" itemprop="name">兔子春</p>
              <p class="site-description motion-element" itemprop="description">热爱生活的程序员</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">81</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/apersonlikesc" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:ztb52cgfls@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heartbeat"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">由一位中二艺术家创作</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">94.8k</span>
  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  







  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/three.min.js"></script>
  

  
  
    <script type="text/javascript" src="/lib/three/canvas_lines.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  
  
  <link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.css">

  
  
  <script src="/lib/needsharebutton/needsharebutton.js"></script>

  <script>
    
      pbOptions = {};
      
          pbOptions.iconStyle = "box";
      
          pbOptions.boxForm = "horizontal";
      
          pbOptions.position = "bottomCenter";
      
          pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Evernote,Mailto";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
    
    
  </script>

  

  

  

  

</body>
</html>
